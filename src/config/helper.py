from collections import OrderedDict

hdict = OrderedDict()
hdict["RESUME"] = "Use Pre-trained model if True, else create and train a model from scratch"
hdict["LINUX_ENV"] = "Automatically set based on execution environment"
hdict["RANDOM_SEED"] = "Default random seed = 42"

hdict["TIER1_PRETRAINED_MODEL"] = "File name (.h5) of the pre-trained model to be used for Tier-1"
hdict["TIER2_PRETRAINED_MODEL"] = "File name (.h5) of the pre-trained model to be used for Tier-2"
hdict["BENIGN"] = "Constant value to represent Benign file type. Do not change !"
hdict["MALWARE"] = "Constant value to represent Malware file type. Do not change !"
hdict["T1_TRAIN_BATCH_SIZE"] = "Batch size to be used for Tier-1 training"
hdict["T2_TRAIN_BATCH_SIZE"] = "Batch size to be used for Tier-2 training"
hdict["PREDICT_BATCH_SIZE"] = "Batch size to be used for prediction - common for both Tier-1&2"

hdict["T1_VERBOSE"] = "Enable-1/Disable-0 verbose for Tier-1"
hdict["T2_VERBOSE"] = "Enable-1/Disable-0 verbose for Tier-2"
hdict["PREDICT_VERBOSE"] = "Enable-1/Disable-0 verbose for prediction - common for both Tier-1&2"
hdict["ATI_PREDICT_VERBOSE"] = "Enable-1/Disable-0 verbose for Activation Trend Identification (ATI) process"
hdict["USE_GPU"] = "Use GPU if True. CPU, otherwise"
hdict["NUM_GPU"] = "Prepares a multi_gpu model if > 1. Deafult - 1"
hdict["GPU_MEM_LIMIT"] = "Option to restrict model's GPU memory consumption. Deafult - 0, no restriction"
hdict["REGENERATE_DATA"] = "Shuffle the list of PE samples in ALL_FILE, split into balanced granular (Benign:Malware) groups and join them to aid partitioning"
hdict["REGENERATE_PARTITIONS"] = "Partition the list of files supplied by max file count or max partition size"
hdict["SKIP_CROSS_VALIDATION"] = "Enable this option, if only data regeneration and partitioning needs to be performed"
hdict["PROJECT_ROOT"] = "Auto-detects project dir name"
hdict["USE_PRETRAINED_FOR_TIER1"] = "Use fresh pre-trained Malconv for Tier-1 if enabled. Else, use the pre-trained Malconv trained over local dataset"
hdict["USE_PRETRAINED_FOR_TIER2"] = "Use fresh pre-trained Malconv for Tier-2 if enabled. Else, use the pre-trained Malconv trained over local dataset"
hdict["PERFORM_B2_BOOSTING"] = "Promotes obvious benign files present in B1 set directly to final result set, if enabled"
hdict["VAL_SET_SIZE"] = "Fraction of the partitions to be used for Validation"
hdict["TST_SET_SIZE"] = "Fraction of the partitions to be used for Testing"
hdict["EPOCHS"] = "Total number of epochs to be used for Tier-1&2 training. Default - 50"
hdict["EARLY_STOPPING_PATIENCE"] = "Early stopping criteria for Training process. Default - 3"
hdict["TIER1_EPOCHS"] = "Default - 1. Number of epochs within a Tier-1 partition. Do not change !"
hdict["TIER2_EPOCHS"] = "Default - 1. Number of epochs within a Tier-2 partition. Do not change !"
hdict["TIER1_TARGET_FPR"] = "Default  = Target FPR required. Same value should be assigned for OVERALL_TARGET_FPR"
hdict["SKIP_ENTIRE_TRAINING"] = "Set to True to skip training process and perform prediction only"
hdict["ONLY_TIER1_TRAINING"] = "Useful to avoid redundant Tier-1 training. If True, trains Tier-1 models across folds, which can then be re-used across different Tier-2 implementations"
hdict["SKIP_TIER1_VALIDATION"] = "Skips Tier-1 validation and regeneration of B1 set for Validation data. Do not enable without completing Tier-1 training and validation at least once."
hdict["SKIP_TIER1_TRAINING_PRED"] = "Skips Tier-1 prediction and regeneration of B1 set for Training data. Do not enable unless this process is completed at least once."
hdict["SKIP_ATI_PROCESSING"] = "Skips ATI process over B1 set of Tier-1 Training data. Do not enable without completing the ATI process at least once."
hdict["TIER_TO_COLLECT_BLOCK_DATA"] = "Default - 1 for Tier-1. Do not change !"
hdict["SKIP_TIER2_CNN_TRAINING"] = "Skips Tier-2 training. Do not enable unless required."
hdict["SKIP_BLOCK_DATA_COLLECTION"] = "Avoids redundant block data collection process on subsequent runs. Can be enabled after completing this step at least once."
hdict["TIER2_TARGET_FPR"] = "Always set to 0 by framework design"
hdict["CV_FOLDS"] = "Number of folds in Cross Validation. Default - 5-fold CV"
hdict["INITIAL_FOLD"] = "Set the fold number to start with. Default - first fold. Useful to run subset of CV folds"
hdict["GRANULARITY_FOR_UNIFORMNESS"] = "Ex: For 10k samples of b:m=1:1 ratio. To ensure each set of, say 500, files from 'shuffled' list to hold fairly 1:1 of b & m, set value as 10k/500=20"
hdict["PARTITION_BY_COUNT"] = "When enabled, initializes a new partition when number of samples reaches MAX_FILES_PER_PARTITION. Otherwise, when MAX_PARTITION_SIZE is reached"
hdict["MAX_PARTITION_SIZE"] = "Maximum allowed size per partition - Recommended = 2GB"
hdict["MAX_FILES_PER_PARTITION"] = "Maximum allowed files per partition"
hdict["MAX_FILE_SIZE_LIMIT"] = "Maximum size of the input samples"
hdict["TIER2_NEW_INPUT_SHAPE"] = "Input shape of Tier-2 model. Default = Number of filters in Tier-1 model * Convolution Stride"
hdict["CONV_WINDOW_SIZE"] = "Size of convolution window used by Tier-1 model"
hdict["CONV_STRIDE_SIZE"] = "Size of convolution stride used by Tier-1 model"
hdict["PROJECT_BASE_PATH"] = "Set the absolute path for the project root"
hdict["DATA_SOURCE_PATH"] = "Set the absolute path for the directory with partitioned data"
hdict["PKL_SOURCE_PATH"] = "Set the absolute path for the directory with t1 and t2 pickle file sub-directories"
hdict["ALL_FILE"] = "Copy of the Raw_To_Pickle.csv. PE sample list in this file will be used for partitioning"
hdict["RAW_SAMPLE_DIRS"] = "Format: { DIR_PATH : IS_BENIGN? } - Dict of Directories with raw samples. Do not keep Benign and Malware samples in same folder"
hdict["DATASET_BACKUP_FILE"] = "Master copy of the curated sample list of supplied dataset. Create a copy and set the copied file's path as ALL_FILE"
hdict["TIER1_MODELS"] = "Name of the trained Tier-1 model"
hdict["TIER2_MODELS"] = "Name of the trained Tier-2 model"
hdict["TENSORBOARD_LOG_PATH"] = "Directory path for Tensorboard logs"
hdict["PLOT_PATH"] = "Path to be used to save generated plots"
hdict["SAVE_PATH"] = "Path to be used to save trained models"
hdict["MODEL_PATH"] = "Path to be used to load models"
hdict["LAYER_NUM_TO_STUNT"] = "Model layer from which data for ATI process to be collected"
hdict["PERCENTILES"] = "Set of intervals that define Q_criteria cut-offs"


class GlobalHelper:
    def show_help(self):
        print(("*" * 92) + "\nPROJECT", ":", "Two Tier Malware Detection For Raw Executables\t[Block-based Implementation]\n" + ("*" * 92))
        print("USAGE:")
        for help_key in hdict:
            print("  ", help_key.ljust(28), ":", hdict[help_key])
